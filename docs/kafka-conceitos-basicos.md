# Kafka - Conceitos B√°sicos

## O que √© Apache Kafka?

Apache Kafka √© uma **plataforma de streaming de eventos distribu√≠da** que permite:
- Publicar e assinar streams de eventos (mensagens)
- Armazenar streams de forma dur√°vel e confi√°vel
- Processar streams em tempo real

Pense no Kafka como um **"sistema nervoso"** que conecta diferentes partes de uma aplica√ß√£o distribu√≠da atrav√©s de eventos.

## Arquitetura Geral

```mermaid
graph TB
    subgraph "Producers"
        P1[Producer 1<br/>Payment Service]
        P2[Producer 2<br/>Order Service]
    end

    subgraph "Kafka Cluster"
        B1[Broker 1]
        B2[Broker 2]
        B3[Broker 3]

        subgraph "Topics"
            T1[Topic: orders]
            T2[Topic: payments]
        end
    end

    subgraph "Consumers"
        C1[Consumer 1<br/>Inventory Service]
        C2[Consumer 2<br/>Notification Service]
    end

    P1 --> B1
    P2 --> B2
    B1 --> C1
    B2 --> C2

    style B1 fill:#4A90E2
    style B2 fill:#4A90E2
    style B3 fill:#4A90E2
```

---

## 1. Broker

### O que √©?
Um **Broker** √© um servidor Kafka. √â o "trabalhador" que armazena e serve as mensagens.

### Caracter√≠sticas:
- Um cluster Kafka geralmente tem **m√∫ltiplos brokers** para redund√¢ncia
- Cada broker √© identificado por um **ID √∫nico**
- Brokers gerenciam as parti√ß√µes e replica√ß√£o dos dados

### Exemplo Pr√°tico:
```yaml
# No seu docker-compose.yml
kafka-service:
  image: confluentinc/cp-server:7.0.1
  environment:
    KAFKA_BROKER_ID: 1  # ID √∫nico deste broker
```

### Analogia:
Pense em um broker como um **servidor de banco de dados** em um cluster distribu√≠do.

---

## 2. Topic (T√≥pico)

### O que √©?
Um **Topic** √© uma categoria ou canal onde os eventos s√£o publicados. √â como uma "fila nomeada" ou "tabela de eventos".

### Caracter√≠sticas:
- Identificado por um **nome √∫nico**
- Pode ter **m√∫ltiplas parti√ß√µes** para paralelismo
- Mensagens s√£o armazenadas por um per√≠odo configur√°vel

### Exemplo Pr√°tico:
```java
// Criando um t√≥pico
String topicName = "order-events";

// Publicando no t√≥pico
producer.send(new ProducerRecord<>("order-events", key, value));

// Consumindo do t√≥pico
consumer.subscribe(Arrays.asList("order-events"));
```

### T√≥picos comuns em um sistema de vendas:
- `order-created` - Quando um pedido √© criado
- `payment-completed` - Quando um pagamento √© processado
- `inventory-reserved` - Quando o estoque √© reservado

### Analogia:
Um topic √© como um **feed de not√≠cias** ou **canal do Slack** - todos que se inscrevem recebem as mensagens.

---

## 3. Partition (Parti√ß√£o)

### O que √©?
Uma **Partition** √© uma subdivis√£o de um topic. Permite paralelismo e escalabilidade.

### Caracter√≠sticas:
- Cada parti√ß√£o √© uma **sequ√™ncia ordenada** de mensagens
- Parti√ß√µes s√£o distribu√≠das entre os brokers
- Mensagens dentro de uma parti√ß√£o mant√™m a **ordem**

### Diagrama de Parti√ß√µes:

```mermaid
graph LR
    subgraph "Topic: order-events"
        P0[Partition 0<br/>msg1‚Üímsg2‚Üímsg3]
        P1[Partition 1<br/>msg4‚Üímsg5‚Üímsg6]
        P2[Partition 2<br/>msg7‚Üímsg8‚Üímsg9]
    end

    B1[Broker 1] -.-> P0
    B2[Broker 2] -.-> P1
    B3[Broker 3] -.-> P2

    style P0 fill:#90EE90
    style P1 fill:#90EE90
    style P2 fill:#90EE90
```

### Exemplo Pr√°tico:
```java
// Producer decide a parti√ß√£o baseado na chave
ProducerRecord<String, String> record =
    new ProducerRecord<>(
        "order-events",    // topic
        customerId,        // key - determina a parti√ß√£o
        orderData          // value
    );

// Mensagens com a mesma key v√£o para a mesma parti√ß√£o
// garantindo ordem por cliente
```

### Por que usar parti√ß√µes?
1. **Paralelismo**: M√∫ltiplos consumidores podem ler parti√ß√µes diferentes simultaneamente
2. **Escalabilidade**: Distribui carga entre brokers
3. **Ordem garantida**: Dentro de cada parti√ß√£o (n√£o entre parti√ß√µes)

---

## 4. Leader e Replica

### O que √©?
Para cada parti√ß√£o, um broker √© o **Leader** e outros s√£o **Replicas** (seguidores).

### Caracter√≠sticas:
- **Leader**: Respons√°vel por todas as leituras e escritas da parti√ß√£o
- **Replicas**: C√≥pias de backup que sincronizam com o leader
- Se o leader falhar, uma replica √© **promovida a leader**

### Diagrama de Replica√ß√£o:

```mermaid
graph TB
    subgraph "Partition 0 - Topic: orders"
        L[Leader<br/>Broker 1<br/>‚úÖ Read/Write]
        R1[Replica<br/>Broker 2<br/>üìã Sync]
        R2[Replica<br/>Broker 3<br/>üìã Sync]
    end

    P[Producer] --> L
    C[Consumer] --> L
    L -.sync.-> R1
    L -.sync.-> R2

    style L fill:#FFD700
    style R1 fill:#B0C4DE
    style R2 fill:#B0C4DE
```

### Configura√ß√£o no docker-compose.yml:
```yaml
KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
```
*Nota: Fator de replica√ß√£o 1 significa sem r√©plicas (apenas para desenvolvimento)*

### Exemplo de Falha e Recupera√ß√£o:

```mermaid
sequenceDiagram
    participant P as Producer
    participant L as Leader (Broker 1)
    participant R as Replica (Broker 2)
    participant Z as Zookeeper/KRaft

    P->>L: Write message
    L->>R: Sync message

    Note over L: Broker 1 crashes! üí•

    Z->>R: Elect as new leader
    Note over R: Promoted to Leader ‚úÖ

    P->>R: Write message (to new leader)
```

---

## 5. Producer (Produtor)

### O que √©?
Uma aplica√ß√£o que **publica** (envia) mensagens para um topic.

### Caracter√≠sticas:
- Decide qual parti√ß√£o usar (baseado na key ou round-robin)
- Pode ter confirma√ß√£o de entrega (acks)
- Buffer interno para batch de mensagens

### Exemplo Pr√°tico:
```java
@Service
public class OrderEventProducer {

    @Autowired
    private KafkaTemplate<String, OrderEvent> kafkaTemplate;

    public void publishOrderCreated(OrderEvent event) {
        // Envia evento para o topic
        kafkaTemplate.send("order-events", event.getOrderId(), event);
    }
}
```

### Configura√ß√µes importantes:
```properties
# Confirma√ß√£o de escrita
acks=all  # Aguarda todas as replicas confirmarem

# Retry
retries=3

# Compress√£o
compression.type=snappy
```

---

## 6. Consumer (Consumidor)

### O que √©?
Uma aplica√ß√£o que **l√™** mensagens de um ou mais topics.

### Caracter√≠sticas:
- Faz parte de um **Consumer Group**
- Mant√©m track do **offset** (posi√ß√£o da √∫ltima mensagem lida)
- Pode processar mensagens em paralelo

### Exemplo Pr√°tico:
```java
@Service
public class OrderEventConsumer {

    @KafkaListener(
        topics = "order-events",
        groupId = "inventory-service"
    )
    public void consumeOrderEvent(OrderEvent event) {
        // Processa o evento
        inventoryService.reserveItems(event.getItems());
    }
}
```

---

## 7. Consumer Group

### O que √©?
Um **Consumer Group** √© um conjunto de consumidores que trabalham juntos para consumir um topic.

### Caracter√≠sticas:
- Cada parti√ß√£o √© consumida por **apenas um consumidor** do group
- Permite escalabilidade horizontal
- Diferentes groups podem consumir o mesmo topic independentemente

### Diagrama de Consumer Groups:

```mermaid
graph TB
    subgraph "Topic: orders (3 partitions)"
        P0[Partition 0]
        P1[Partition 1]
        P2[Partition 2]
    end

    subgraph "Consumer Group: inventory-service"
        C1[Consumer 1]
        C2[Consumer 2]
    end

    subgraph "Consumer Group: notification-service"
        C3[Consumer 3]
    end

    P0 --> C1
    P1 --> C1
    P2 --> C2

    P0 --> C3
    P1 --> C3
    P2 --> C3

    style C1 fill:#98D8C8
    style C2 fill:#98D8C8
    style C3 fill:#F7B801
```

### Exemplo de Escalabilidade:
```
Topic com 3 parti√ß√µes:

1 Consumer no group:
  Consumer 1 ‚Üí P0, P1, P2 (l√™ todas)

2 Consumers no group:
  Consumer 1 ‚Üí P0, P1
  Consumer 2 ‚Üí P2

3 Consumers no group:
  Consumer 1 ‚Üí P0
  Consumer 2 ‚Üí P1
  Consumer 3 ‚Üí P2

4 Consumers no group:
  Consumer 1 ‚Üí P0
  Consumer 2 ‚Üí P1
  Consumer 3 ‚Üí P2
  Consumer 4 ‚Üí (idle) ‚ö†Ô∏è Mais consumers que parti√ß√µes!
```

---

## 8. Offset

### O que √©?
O **Offset** √© um n√∫mero sequencial √∫nico que identifica cada mensagem dentro de uma parti√ß√£o.

### Caracter√≠sticas:
- Come√ßa em 0 e incrementa sequencialmente
- Cada consumer group mant√©m seu pr√≥prio offset
- Permite reprocessamento de mensagens

### Diagrama de Offsets:

```mermaid
graph LR
    subgraph "Partition 0"
        M0[Offset: 0<br/>msg1]
        M1[Offset: 1<br/>msg2]
        M2[Offset: 2<br/>msg3]
        M3[Offset: 3<br/>msg4]
        M4[Offset: 4<br/>msg5]
    end

    C1[Consumer Group A<br/>Last read: 2] -.-> M2
    C2[Consumer Group B<br/>Last read: 4] -.-> M4

    style M2 fill:#90EE90
    style M4 fill:#FFB6C1
```

### Exemplo Pr√°tico:
```java
// Commit manual do offset
@KafkaListener(topics = "orders")
public void consume(ConsumerRecord<String, Order> record) {
    processOrder(record.value());

    // S√≥ commita o offset se processou com sucesso
    acknowledgment.acknowledge();
}
```

### Estrat√©gias de Commit:
- **Auto-commit**: Kafka commita automaticamente (pode perder mensagens)
- **Manual-commit**: Aplica√ß√£o controla quando committar (mais seguro)

---

## 9. Mensagens s√£o Apagadas ao Serem Consumidas?

### Resposta Curta: N√ÉO!

**Diferente de filas tradicionais**, quando um consumer l√™ uma mensagem no Kafka, ela **N√ÉO √© apagada**. Apenas o **offset √© movido**.

### Como Funciona:

```mermaid
graph LR
    subgraph "Partition 0 - Topic: orders"
        M0[Offset 0<br/>msg1<br/>üìÖ Day 1]
        M1[Offset 1<br/>msg2<br/>üìÖ Day 1]
        M2[Offset 2<br/>msg3<br/>üìÖ Day 2]
        M3[Offset 3<br/>msg4<br/>üìÖ Day 2]
        M4[Offset 4<br/>msg5<br/>üìÖ Day 3]
    end

    C1[Consumer Group A<br/>offset: 2] -.ler.-> M2
    C2[Consumer Group B<br/>offset: 4] -.-> M4

    Note[üíæ Todas as mensagens<br/>ainda existem no disco!]

    style M0 fill:#D3D3D3
    style M1 fill:#D3D3D3
    style M2 fill:#90EE90
    style M3 fill:#D3D3D3
    style M4 fill:#FFB6C1
```

### Kafka vs Fila Tradicional

#### Fila Tradicional (RabbitMQ, SQS):
```
Producer ‚Üí [msg1, msg2, msg3] ‚Üí Consumer
                                    ‚Üì
                     [msg2, msg3]  (msg1 apagada!)
```

#### Kafka (Log Distribu√≠do):
```
Producer ‚Üí [msg1, msg2, msg3, msg4, msg5...] ‚Üí Consumer 1 (offset: 2)
                                              ‚Üí Consumer 2 (offset: 4)
                                              ‚Üí Consumer 3 (offset: 1)

üíæ Todas as mensagens continuam no disco!
```

### Quando as Mensagens S√ÉO Apagadas?

Mensagens s√£o apagadas **automaticamente** por pol√≠tica de reten√ß√£o, **independente de terem sido consumidas ou n√£o**:

#### 1. Reten√ß√£o por Tempo (padr√£o: 7 dias)
```properties
# Configura√ß√£o do topic
retention.ms=604800000  # 7 dias em milissegundos

# Depois de 7 dias, a mensagem √© deletada automaticamente
```

#### 2. Reten√ß√£o por Tamanho
```properties
retention.bytes=1073741824  # 1 GB

# Quando o topic atingir 1GB, mensagens antigas s√£o deletadas
```

#### 3. Configura√ß√£o no docker-compose.yml:
```yaml
kafka-service:
  environment:
    KAFKA_LOG_RETENTION_HOURS: 168  # 7 dias
    KAFKA_LOG_RETENTION_BYTES: -1   # Ilimitado (-1)
```

### Vantagens dessa Abordagem

#### 1. M√∫ltiplos Consumidores Independentes
```java
// Consumer Group 1: Inventory Service
@KafkaListener(topics = "order-created", groupId = "inventory-service")
public void consumeInventory(OrderEvent event) {
    inventoryService.reserve(event);
}

// Consumer Group 2: Notification Service
@KafkaListener(topics = "order-created", groupId = "notification-service")
public void consumeNotification(OrderEvent event) {
    notificationService.send(event);
}

// Ambos leem as MESMAS mensagens!
// Cada group mant√©m seu pr√≥prio offset
```

#### 2. Replay de Mensagens (Reprocessamento)
```java
// Voc√™ pode "voltar no tempo" e reprocessar mensagens antigas!
consumer.seek(partition, 0);  // Volta para o offset 0

// √ötil para:
// - Corrigir bugs reprocessando eventos
// - Reconstruir cache ou √≠ndices
// - An√°lise retrospectiva de dados
```

#### 3. Event Sourcing
```java
// Reconstruir o estado completo lendo todos os eventos desde o in√≠cio
public Order rebuildOrderState(String orderId) {
    consumer.seek(partition, 0);  // In√≠cio
    List<OrderEvent> allEvents = consumer.poll();

    return allEvents.stream()
        .filter(e -> e.getOrderId().equals(orderId))
        .reduce(new Order(), (order, event) -> order.apply(event));
}
```

### Diagrama: M√∫ltiplos Consumers Lendo as Mesmas Mensagens

```mermaid
sequenceDiagram
    participant P as Producer
    participant K as Kafka
    participant C1 as Consumer Group 1
    participant C2 as Consumer Group 2

    P->>K: Send msg1
    P->>K: Send msg2
    P->>K: Send msg3

    Note over K: Mensagens armazenadas:<br/>[msg1, msg2, msg3]

    C1->>K: Read (offset: 0)
    K->>C1: msg1
    Note over C1: offset = 1

    C2->>K: Read (offset: 0)
    K->>C2: msg1
    Note over C2: offset = 1

    Note over K: üíæ msg1 ainda existe!<br/>Ambos consumidores leram ela

    C1->>K: Read (offset: 1)
    K->>C1: msg2

    C2->>K: Read (offset: 1)
    K->>C2: msg2

    Note over K: üíæ msg1, msg2, msg3<br/>Todas ainda existem!
```

### Compara√ß√£o: Kafka vs Fila Tradicional

| Aspecto | Kafka | Fila Tradicional (RabbitMQ, SQS) |
|---------|-------|----------------------------------|
| **Mensagem ap√≥s consumo** | ‚úÖ Permanece at√© expirar | ‚ùå Apagada imediatamente |
| **M√∫ltiplos consumers** | ‚úÖ Sim (via consumer groups) | ‚ö†Ô∏è Limitado (fanout exchange) |
| **Replay/Reprocessamento** | ‚úÖ Sim, volte no tempo | ‚ùå N√£o √© poss√≠vel |
| **Quando apaga** | ‚è∞ Ap√≥s pol√≠tica de reten√ß√£o | üîÑ Ap√≥s ACK do consumer |
| **Offset/Posi√ß√£o** | ‚úÖ Por consumer group | ‚ùå N√£o aplic√°vel |
| **Event Sourcing** | ‚úÖ Ideal | ‚ö†Ô∏è N√£o recomendado |
| **Ordena√ß√£o** | ‚úÖ Por parti√ß√£o | ‚ö†Ô∏è Limitada |
| **Throughput** | ‚úÖ Milh√µes/seg | ‚ö†Ô∏è Milhares/seg |

### Exemplo Pr√°tico: Reprocessamento ap√≥s Bug Fix

```java
// Cen√°rio: Bug no c√°lculo de desconto foi corrigido
// Queremos reprocessar pedidos dos √∫ltimos 3 dias

@Service
public class OrderReprocessingService {

    public void reprocessOrders() {
        // 1. Cria um consumer tempor√°rio
        KafkaConsumer<String, OrderEvent> consumer = createConsumer();

        // 2. Calcula offset de 3 dias atr√°s
        long threeDaysAgo = System.currentTimeMillis() - (3 * 24 * 60 * 60 * 1000);
        Map<TopicPartition, Long> timestamps = consumer.offsetsForTimes(
            Collections.singletonMap(
                new TopicPartition("order-created", 0),
                threeDaysAgo
            )
        );

        // 3. Reposiciona o offset
        timestamps.forEach((partition, offsetAndTimestamp) -> {
            consumer.seek(partition, offsetAndTimestamp);
        });

        // 4. Reprocessa mensagens
        while (true) {
            ConsumerRecords<String, OrderEvent> records = consumer.poll(Duration.ofSeconds(1));
            for (ConsumerRecord<String, OrderEvent> record : records) {
                // Aplica novo c√°lculo de desconto
                recalculateDiscount(record.value());
            }
        }
    }
}
```

### Resumo

**Kafka funciona como um log append-only (somente adi√ß√£o) que mant√©m hist√≥rico!**

- Mensagens **N√ÉO s√£o apagadas** quando consumidas
- Cada consumer group rastreia seu pr√≥prio **offset**
- Mensagens expiram baseado em **tempo** ou **tamanho**, n√£o em consumo
- Permite **m√∫ltiplos consumidores** independentes
- Possibilita **replay** e **event sourcing**
- Ideal para arquiteturas orientadas a eventos e microservices

---

## Fluxo Completo de uma Mensagem

```mermaid
sequenceDiagram
    participant P as Producer<br/>(Payment Service)
    participant B as Broker<br/>(Leader)
    participant R as Replica<br/>(Follower)
    participant C as Consumer<br/>(Inventory Service)
    participant O as Offset Store

    P->>B: 1. Send message<br/>topic: payment-completed
    B->>R: 2. Replicate
    R->>B: 3. ACK
    B->>P: 4. ACK (all replicas)

    C->>B: 5. Poll messages
    B->>C: 6. Return messages
    C->>C: 7. Process message
    C->>O: 8. Commit offset

    Note over B: üíæ Mensagem permanece<br/>at√© pol√≠tica de reten√ß√£o
```

---

## Exemplo Pr√°tico: Sistema de Pedidos

### Cen√°rio:
Um cliente faz um pedido que precisa:
1. Reservar estoque
2. Processar pagamento
3. Enviar notifica√ß√£o

### Fluxo com Kafka:

```mermaid
graph LR
    A[Order Service] -->|order-created| B[Kafka]
    B -->|consume| C[Inventory Service]
    B -->|consume| D[Payment Service]
    B -->|consume| E[Notification Service]

    C -->|inventory-reserved| B
    D -->|payment-processed| B
    E -->|notification-sent| B

    style B fill:#4A90E2
```

### C√≥digo do Producer:
```java
// Order Service
@Service
public class OrderService {

    public void createOrder(Order order) {
        // 1. Salva no banco
        orderRepository.save(order);

        // 2. Publica evento
        OrderCreatedEvent event = new OrderCreatedEvent(
            order.getId(),
            order.getCustomerId(),
            order.getItems()
        );

        kafkaTemplate.send("order-created", order.getId(), event);
    }
}
```

### C√≥digo do Consumer:
```java
// Inventory Service
@Service
public class InventoryEventConsumer {

    @KafkaListener(
        topics = "order-created",
        groupId = "inventory-service"
    )
    public void handleOrderCreated(OrderCreatedEvent event) {
        // Reserva itens do estoque
        inventoryService.reserve(event.getItems());

        // Publica evento de confirma√ß√£o
        kafkaTemplate.send("inventory-reserved", event.getOrderId(), ...);
    }
}
```

---

## Configura√ß√£o no seu docker-compose.yml

```yaml
kafka-service:
  image: confluentinc/cp-server:7.0.1
  environment:
    # ID √∫nico deste broker
    KAFKA_BROKER_ID: 1

    # Listeners (portas de comunica√ß√£o)
    KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092

    # Replica√ß√£o (1 = sem r√©plicas, apenas dev)
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
```

---

## Principais Vantagens do Kafka

1. **Alta Performance**: Milh√µes de mensagens por segundo
2. **Durabilidade**: Mensagens persistidas em disco
3. **Escalabilidade**: Adicione brokers e parti√ß√µes conforme necess√°rio
4. **Toler√¢ncia a Falhas**: Replica√ß√£o autom√°tica
5. **Desacoplamento**: Produtores e consumidores independentes
6. **Replay**: Possibilidade de reprocessar mensagens antigas

---

## Quando Usar Kafka?

### ‚úÖ Ideal para:
- Event sourcing e CQRS
- Saga pattern (como no seu projeto!)
- Streaming de dados em tempo real
- Log aggregation
- Microservices communication
- Activity tracking

### ‚ö†Ô∏è N√£o ideal para:
- Request/response s√≠ncrono (use REST/gRPC)
- Mensagens que expiram rapidamente
- Poucos eventos (overhead desnecess√°rio)
- Processamento transacional direto

---

## Gloss√°rio R√°pido

| Termo | Defini√ß√£o |
|-------|-----------|
| **Broker** | Servidor Kafka que armazena mensagens |
| **Topic** | Canal/categoria de mensagens |
| **Partition** | Subdivis√£o de um topic para paralelismo |
| **Leader** | Broker respons√°vel por uma parti√ß√£o |
| **Replica** | C√≥pia de backup de uma parti√ß√£o |
| **Producer** | Aplica√ß√£o que publica mensagens |
| **Consumer** | Aplica√ß√£o que l√™ mensagens |
| **Consumer Group** | Grupo de consumidores trabalhando juntos |
| **Offset** | Posi√ß√£o sequencial de uma mensagem |
| **Zookeeper** | Servi√ßo de coordena√ß√£o (vers√µes antigas) |
| **KRaft** | Modo sem Zookeeper (vers√µes novas) |

---

## Pr√≥ximos Passos

1. Explore o Kafka UI dispon√≠vel em: http://localhost:8181
2. Veja os t√≥picos criados pelo seu sistema
3. Monitore mensagens em tempo real
4. Experimente criar t√≥picos manualmente

## Refer√™ncias

- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Confluent Documentation](https://docs.confluent.io/)
- [Kafka: The Definitive Guide](https://www.confluent.io/resources/kafka-the-definitive-guide/)
